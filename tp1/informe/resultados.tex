\newcommand\MyBox[2]{
  \fbox{\lower0.75cm
    \vbox to 1.7cm{\vfil
      \hbox to 1.7cm{\hfil\parbox{1.4cm}{#1\\#2}\hfil}
      \vfil}%
  }%
}

\noindent
\renewcommand\arraystretch{1.5}
\setlength\tabcolsep{0pt}

\section{Resultados}
A la hora de experimentar, decidimos utilizar el método \textbf{grid search} combinado con \textbf{cross validation}, provisto por la librería \textit{sklearn} de python.
Este método se encarga de armar un clasificador por cada combinación de parámetros que se le pasan y luego aplica la estrategia de \textbf{KFold} (con k = 10), la cual
consiste en particionar nuestro conjunto de datos de test en 10 subconjuntos, y entrenar sobre 9 de ellos, dejando un subconjunto para testear.\\

Una herramienta utilizada para simplificar el entrenamiento del modelo fue la clase \textit{Pipeline}, provista por la
libreria pipeline de sklearn. Esto nos permitio separar el entrenamiento del modelo en distintas etapas de un pipeline,
con el objetivo de modularizar el proceso de entrenamiento. \\

Otra decisión que tomamos al experimentar, fue la de tomar la mitad del set de datos(45K mails) como datos de desarrollo y la otra mitad como datos
de test. Esta decisión fue tomada con el objetivo de obtener una estimación mas realista sobre la performance utilizada y ademas en muchos de los modelos
utilizados, entrenar sobre una cantidad de datos tan grande puede llegar a tardar demasiado.

Los analisis de resultados y los scores que presentaremos a continuación siguen la metrica \textbf{f1}, ya que consideramos
que esta es la metrica adecuada para maximizar.

\subsection{Decision Tree}
En el caso de Decision Tree la mejor configuración de parametros que obtuvimos con el grid search fue la siguiente:
\begin{itemize}
\item{fit\_prior: True}
\item{alpha: 0}
\end{itemize}

Obteniendo un score de 0.9772 y la siguiente matriz de confusion:

 \begin{tabular}{c >{\bfseries}r @{\hspace{0.7em}}c @{\hspace{0.4em}}c @{\hspace{0.7em}}l}
   \multirow{10}{*}{\parbox{1.1cm}{\bfseries\raggedleft}} &
   & \multicolumn{2}{c}{\bfseries Descision Tree} & \\
   & & \bfseries Spam(Predicho) & \bfseries No Spam(Predicho) & \bfseries \\
   & Spam(Real) & \MyBox{22130}{} & \MyBox{370}{} & \\[2.4em]
   & No Spam(Real) & \MyBox{649}{} & \MyBox{21851}{} & \\
 \end{tabular} \\\\

Una observacion realizada fue que los árboles tienen el problema de ser condicionados a favor de la clase mayoritaria
del dataset, y, aunque en general esto no es bueno, en nuestro caso particular de tener más emails válidos que spam no
nos trae problemas, porque es peor identificarlos como spam (\textit{false positive}) que errar por preacución
(\textit{false negative}).

\subsection{SVM}

En el caso de random forest la mejor configuración de parametros que obtuvimos con el grid search fue la siguiente:
\begin{itemize}
\item{kernel: l}
\item{C: 3.5}
\end{itemize}

Obteniendo un score de 0.9479 y la siguiente matriz de confusion:

 \begin{tabular}{c >{\bfseries}r @{\hspace{0.7em}}c @{\hspace{0.4em}}c @{\hspace{0.7em}}l}
   \multirow{10}{*}{\parbox{1.1cm}{\bfseries\raggedleft}} &
   & \multicolumn{2}{c}{\bfseries SVM} & \\
   & & \bfseries Spam(Predicho) & \bfseries No Spam(Predicho) & \bfseries \\
   & Spam(Real) & \MyBox{21979}{} & \MyBox{521}{} & \\[2.4em]
   & No Spam(Real) & \MyBox{1759}{} & \MyBox{20741}{} & \\
 \end{tabular}



\subsection{Random Forest}
En el caso de random forest la mejor configuración de parametros que obtuvimos con el grid search fue la siguiente:
\begin{itemize}
\item{max\_features: "sqrt"}
\item{n\_estimators: 15}
\item{criterion: "entropy"}
\end{itemize}

Obteniendo un score de 0.9801 y la siguiente matriz de confusion:

 \begin{tabular}{c >{\bfseries}r @{\hspace{0.7em}}c @{\hspace{0.4em}}c @{\hspace{0.7em}}l}
   \multirow{10}{*}{\parbox{1.1cm}{\bfseries\raggedleft}} &
   & \multicolumn{2}{c}{\bfseries Random Forest} & \\
   & & \bfseries Spam(Predicho) & \bfseries No Spam(Predicho) & \bfseries \\
   & Spam(Real) & \MyBox{22339}{} & \MyBox{161}{} & \\[2.4em]
   & No Spam(Real) & \MyBox{720}{} & \MyBox{21780}{} & \\
 \end{tabular}

\section{K Nearest Neighbors}
Para este caso cabe mencionar que los resultados que presentaremos a continuación fueron obtenidos
a partir de la experimentación sin usar el método de reducción de dimensionalidad. Esto se debe a que
cuando experimentamos con la reduccion de los KBest, nuestro modelo entrenaba de manera correcta seleccionando
 una mejor configuracion de parametros, pero a la hora de predecir resultados sobre nuestros datos de test,
obteniamos un error de memoria. Para tratar de solucionar esto decidimos bajar la cantidad de features de 100 a 50
y finalmente a 20, obteniendo en todos los casos el mismo error. \\
Otra decision tomada a la hora de experimentar fue la de utilizar una cantidad acotada de vecinos(es decir un bajo valor de k),
ya que al ser una base de datos con 90K mails, este clasificador tarda demasiado en terminar y en muchos
casos se obtienen errores de memoria, ya que debe calcular la distancia de la nueva instancia contra todas los demas.


Teniendo en cuenta estas consideraciones obtuvimos la siguiente configuracion de parametros como la mejor:

\begin{itemize}
  \item{n\_neighbors: 5}
  \item{weights: "distance"}
\end{itemize}

Obteniendo un score de 0.9866 y la siguiente matriz de confusion:

\begin{tabular}{c >{\bfseries}r @{\hspace{0.7em}}c @{\hspace{0.4em}}c @{\hspace{0.7em}}l}
  \multirow{10}{*}{\parbox{1.1cm}{\bfseries\raggedleft}} &
  & \multicolumn{2}{c}{\bfseries K Nearest Neighbors} & \\
  & & \bfseries Spam(Predicho) & \bfseries No Spam(Predicho) & \bfseries \\
  & Spam(Real) & \MyBox{22171}{} & \MyBox{329}{} & \\[2.4em]
  & No Spam(Real) & \MyBox{272}{} & \MyBox{22228}{} & \\
\end{tabular}\\\\

Una conclusión importante que obtuvimos al experimentar con diversos \textit{k}, fue que a medidad que este aumentaba,
el score obtenido disminuia de manera proporcional. Es por esto que el grid search eligio un \textit{k} muy bajo como el mejor.

Otra particularidad que notamos, fue que al usar el algoritmo de \textit{distance} para calcular la distancia a los vecinos mas cercanos,
los resultados fueron mejores que al hacerlo con el método \textit{uniform}.

\subsection{Naive Bayes - Gaussian}

En este caso, como mencionamos mas arriba, no tenemos ningun parametro por variar. \\

Obteniendo un score de 0.7407 y la siguiente matriz de confusion:

 \begin{tabular}{c >{\bfseries}r @{\hspace{0.7em}}c @{\hspace{0.4em}}c @{\hspace{0.7em}}l}
   \multirow{10}{*}{\parbox{1.1cm}{\bfseries\raggedleft}} &
   & \multicolumn{2}{c}{\bfseries Naive Bayes Gaussian} & \\
   & & \bfseries Spam(Predicho) & \bfseries No Spam(Predicho) & \bfseries \\
   & Spam(Real) & \MyBox{21800}{} & \MyBox{700}{} &\\[2.4em]
   & No Spam(Real) & \MyBox{8855}{} & \MyBox{13645}{} &\\
 \end{tabular}


\subsection{Naive Bayes - Multinomial}

En el caso de Naive Bayes - Multinomial la mejor configuración de parametros que obtuvimos con el grid search fue la siguiente:
\begin{itemize}
\item{fit\_prior: True}
\item{alpha: 0}
\end{itemize}

Obteniendo un score de 0.8155 y la siguiente matriz de confusion:

 \begin{tabular}{c >{\bfseries}r @{\hspace{0.7em}}c @{\hspace{0.4em}}c @{\hspace{0.7em}}l}
   \multirow{10}{*}{\parbox{1.1cm}{\bfseries\raggedleft}} &
   & \multicolumn{2}{c}{\bfseries Naive Bayes Multinomial} & \\
   & & \bfseries Spam(Predicho) & \bfseries No Spam(Predicho) & \bfseries \\
   & Spam(Real) & \MyBox{21052}{} & \MyBox{1448}{} &  \\[2.4em]
   & No Spam(Real) & \MyBox{6011}{} & \MyBox{16489}{} &  \\
 \end{tabular}
